{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TENSORFLOW.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1yxXWnNsty7maXSIITKDJZ2lXVOQAp6bf",
      "authorship_tag": "ABX9TyNp6miZzPK6atRyR4OKT1zG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SandboxGTASA/0478_22_FebMarch_Pizza/blob/main/TENSORFLOW.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CwTbI0OPVF2v"
      },
      "source": [
        "# Arquivo de treinamento e predicão do modelo de IA do programa IA Trader\n",
        "# Autor: Matheus Lemos <matheuslemosf@gmail.com>\n",
        "\n",
        "from os import environ\n",
        "environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras import layers, optimizers, Sequential, models\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Uso de outro modelo\n",
        "from sklearn.svm import SVR\n",
        "\n",
        "class Model:\n",
        "    \"\"\"\n",
        "    Classe que define o modelo de machine learning\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,datasetName=None):\n",
        "        \"\"\"\n",
        "        Assignment de variáveis\n",
        "        \"\"\"\n",
        "\n",
        "        self.datasetName = datasetName\n",
        "\n",
        "    def splitData(self, data, trainTestSplit):\n",
        "        \"\"\"\n",
        "        Divide em dados de treinamento (train) e teste (test)\n",
        "\n",
        "        Arguments:\n",
        "            dataset {Pandas.DataFrame} -- DataFrame do pandas com os dados do dataset\n",
        "\n",
        "        Returns:\n",
        "            trainDataset {pandas.DataFrame} -- Dataset de treino\n",
        "            trainDataset {pandas.DataFrame} -- Dataset de treino\n",
        "            testDataset {pandas.DataFrame} -- Labels de treino\n",
        "            testDataset {pandas.DataFrame} -- Labels de treino\n",
        "        \"\"\"\n",
        "\n",
        "        # Carregamento dos dados\n",
        "        trainDataset = data.sample(frac=trainTestSplit, random_state=1)\n",
        "        testDataset = data.drop(trainDataset.index)\n",
        "        trainLabels = trainDataset.pop('fechamento')\n",
        "        testLabels = testDataset.pop('fechamento')\n",
        "\n",
        "        return trainDataset, testDataset, trainLabels, testLabels\n",
        "\n",
        "    def plotHistory(self, history):\n",
        "        \"\"\"\n",
        "        Gera gráfico do histórico de treino (fit)\n",
        "\n",
        "        Arguments:\n",
        "            history {} -- Histórico de treino do keras.Sequential\n",
        "        \"\"\"\n",
        "\n",
        "        hist = pd.DataFrame(history.history)\n",
        "        hist['epoch'] = history.epoch\n",
        "\n",
        "        plt.figure()\n",
        "        plt.xlabel('Época')\n",
        "        plt.ylabel('Média do erro absoluto')\n",
        "        plt.plot(hist['epoch'], hist['mae'], label='Erro de treino')\n",
        "        plt.plot(hist['epoch'], hist['val_mae'], label='Erro de validacão')\n",
        "        plt.legend()\n",
        "        \n",
        "        plt.figure()\n",
        "        plt.xlabel('Época')\n",
        "        plt.ylabel('Média do erro absoluto')\n",
        "        plt.plot(hist['epoch'], hist['mse'], label='Erro de treino')\n",
        "        plt.plot(hist['epoch'], hist['val_mse'], label='Erro de validacão')\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "    def load(self, dayDict):\n",
        "        \"\"\"\n",
        "        Carrega o dataset a partir de arquivo CSV\n",
        "\n",
        "        Arguments:\n",
        "            dayDict {dict} -- Dicionário com os dias válidos de predicão, para fins de normalizacão\n",
        "    \n",
        "        Returns:\n",
        "            df {pandas.DataFrame} -- DataFrame do pandas com os dados carregados e filtrados\n",
        "        \"\"\"\n",
        "\n",
        "        # Busca dados no intervalo de tempo passado e remove colunas não necessárias\n",
        "        precision = 4\n",
        "        df = pd.read_csv(self.datasetName)\n",
        "        df['fechamento'] = df['fechamento'].round(decimals=precision)\n",
        "        \n",
        "        # Faz o mapeamento de datas para valores\n",
        "\n",
        "        df['dia'] = df['dia'].apply(lambda x: dayDict[str(x)])\n",
        "\n",
        "        return df\n",
        "\n",
        "    def normalize(self, data):\n",
        "        \"\"\" Normaliza os dados por coluna\n",
        "\n",
        "        Arguments:\n",
        "            data {pandas.DataFrame} -- DataFrame do pandas com os dados brutos\n",
        "\n",
        "        Returns:\n",
        "            data {pandas.DataFrame} -- DataFrame do pandas com os dados normalizados\n",
        "        \"\"\"\n",
        "\n",
        "        data['dia'] = (data['dia'] - data['dia'].mean()) / (data['dia'].max() - data['dia'].min())\n",
        "        data['hora'] = (data['hora'] - data['hora'].mean()) / (data['hora'].max() - data['hora'].min())\n",
        "        return data\n",
        "\n",
        "    def write(self, fileName, data):\n",
        "        \"\"\" Escreve o DataFrame em um arquivo CSV\n",
        "\n",
        "        Arguments:\n",
        "            fileName {str} -- Caminho do arquivo no sistema de arquivos onde os dados serão escritos\n",
        "            data {pandas.DataFrame} -- DataFrame do pandas com os dados a serem escritos\n",
        "        \"\"\"\n",
        "        data.to_csv(fileName, header=True, index=False)\n",
        "\n",
        "\n",
        "    def fit(self, trainDataset, trainLabels, parameters):\n",
        "        \"\"\"\n",
        "        Faz o treinamento do modelo e escreve os pesos em arquivo\n",
        "        \n",
        "        Arguments:\n",
        "            trainDataset {pandas.DataFrame} -- Dataset de treino\n",
        "            trainLabel {pandas.DataFrame} -- Labels de treino\n",
        "            parameters {dict} -- Parâmetros de treinamento\n",
        "        \"\"\"\n",
        "\n",
        "        # Variáveis\n",
        "        epochs = int(parameters['epochs'])\n",
        "       \n",
        "        # Definicão do modelo\n",
        "        model = Sequential([\n",
        "            layers.Dense(24, kernel_initializer='normal', input_shape=[len(trainDataset.keys())]),\n",
        "            layers.Dropout(0.5),\n",
        "            layers.Dense(24, kernel_initializer='normal', activation='relu'),\n",
        "            layers.Dense(1, kernel_initializer='normal')\n",
        "        ])\n",
        "        \n",
        "        optimizer = optimizers.RMSprop(0.001)\n",
        "        model.compile(loss='mse', optimizer=optimizer, metrics=['mae', 'mse'])\n",
        "        model.summary()\n",
        "\n",
        "        # Treino do modelo\n",
        "        history = model.fit(trainDataset, trainLabels, epochs=epochs, validation_split=0.2)\n",
        "\n",
        "        # Salva o modelo em um arquivo\n",
        "        model.save(parameters['modelfile'])\n",
        "        \n",
        "        # ESSA PARTE PODE SER DESCOMENTADA CASO DESEJE VER O GRÁFICO DE TREINAMENTO\n",
        "        # Imprime o resultado em um gráfico\n",
        "        #self.plotHistory(history)\n",
        "\n",
        "    def predict(self, testDataset, testLabels, parameters):\n",
        "        \"\"\"\n",
        "        Faz a predicão a partir dos dados de teste e gera gráfico \n",
        "        \n",
        "        Arguments:\n",
        "            testDataset {pandas.DataFrame} -- Dataset de teste \n",
        "            testLabel {pandas.DataFrame} -- Labels de teste\n",
        "            parameters {dict} -- Dicionário com parâmetros de configuracão\n",
        "        \"\"\"\n",
        "\n",
        "        # Carrega o modelo\n",
        "        model = models.load_model(parameters['modelfile'])\n",
        "\n",
        "        # Faz a predicão\n",
        "        precision = 4\n",
        "        predictions = model.predict(testDataset);\n",
        "\n",
        "        # Avalia os resultados e imprime em tela\n",
        "        predictedLabels = predictions.flatten()\n",
        "        r2 = r2_score(testLabels, predictedLabels)\n",
        "        mse = mean_squared_error(testLabels, predictedLabels)\n",
        "        print(\"\\n===== AVALIACÕES =====\")\n",
        "        print(f\"R2-Score: {r2}\")\n",
        "        print(f\"MSE: {mse}\\n\")\n",
        "        \n",
        "        # Converte para dataframe\n",
        "        predictions = np.array([float(val) for sublist in predictions for val in sublist])\n",
        "        predictions = [round(elem, precision) for elem in predictions]\n",
        "        \n",
        "        horas = np.array(testDataset['hora'].tolist())\n",
        "        dias = np.array(testDataset['dia'].tolist())\n",
        "        arr = np.array((predictions, dias, horas)).T\n",
        "\n",
        "        df = pd.DataFrame(arr, columns=['fechamento', 'dia', 'hora'])   \n",
        "        return df\n",
        "\n",
        "    def validate(self, dia, parameters, dayDict):\n",
        "        \"\"\" Cria previsões de valores do ativo para o dia passado como parâmetro\n",
        "\n",
        "        Arguments:\n",
        "            dia {int} -- Dia para que se deseja realizar as previsões\n",
        "            parameters {dict} -- Dicionário de parâmetros do arquivo de configuracão\n",
        "            dayDict {dict} -- Dicionário com todos os dias válidos para fins de validacão\n",
        "        \"\"\"\n",
        "\n",
        "        # Carrega o modelo\n",
        "        model = models.load_model(parameters['modelfile'])\n",
        "    \n",
        "        # Gera um DataFrame com os minutos de abertura da bolsa\n",
        "        initMinute = 0\n",
        "        endMinute = 59\n",
        "        initHour = 900\n",
        "        endHour = 1700\n",
        "        i = initHour\n",
        "        j = initMinute\n",
        "        horas = []\n",
        "        while i <= endHour:\n",
        "            j = initMinute\n",
        "            while j <= endMinute:\n",
        "                horas.append(i + j)\n",
        "                j += 1\n",
        "            i += 100\n",
        "            \n",
        "        del horas[0:5]\n",
        "        lenHoras = len(horas)\n",
        "        dias = [int(dia)] * lenHoras\n",
        "        \n",
        "        horas = np.array(horas)\n",
        "        dias = np.array(dias)\n",
        "        arr = np.array((horas, dias)).T\n",
        "        df = pd.DataFrame(arr, columns=['hora', 'dia'])\n",
        "        print('dayDict')\n",
        "        print(dayDict)\n",
        "        print('df')\n",
        "        print('Transforma o dia baseado no dicionário de dias ')\n",
        "        # Transforma o dia baseado no dicionário de dias \n",
        "        df['dia'] = df['dia'].apply(lambda x: dayDict[str(x)])\n",
        "        \n",
        "        normalized  = df.copy()\n",
        "        print('Carrega os dados de treinamento anteriores')\n",
        "        # Carrega os dados de treinamento anteriores\n",
        "        trainData = pd.read_csv('traindata.csv')\n",
        "        \n",
        "        # Normaliza os dados\n",
        "        normalized['dia'] = (normalized['dia'] - trainData['dia'].mean()) / (trainData['dia'].max() - trainData['dia'].min())\n",
        "        normalized['hora'] = (normalized['hora'] - trainData['hora'].mean()) / (trainData['hora'].max() - trainData['hora'].min())\n",
        "\n",
        "        # Realiza a predicão\n",
        "        prediction = model.predict(normalized).flatten()\n",
        "\n",
        "        df['previsao'] = prediction\n",
        "        print(df)\n",
        "\n",
        "        # Escreve os dados\n",
        "        predictionsFile = f'predictions/previsoes-{dia}.csv'\n",
        "        df.to_csv(predictionsFile, header=True, index=False)"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MjjDd-jBpHW4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-PwhSCGqW3R3"
      },
      "source": [
        "# Utilitário de interacão com arquivos\n",
        "# Autor: Matheus Lemos <matheuslemosf@gmail.com>\n",
        "\n",
        "import json\n",
        "\n",
        "class FileDriver():\n",
        "    \"\"\" Classe que interage com arquivos\n",
        "    \"\"\"\n",
        "\n",
        "    def readJson(self, fileName):\n",
        "        \"\"\" Método que faz a leitura de arquivos JSON e armazena em um dicionário\n",
        "\n",
        "        Arguments:\n",
        "            fileName {str} -- Caminho do arquivo no sistema de arquivos\n",
        "\n",
        "        Returns:\n",
        "            data {dict} -- Dicionário com os dados lidos do arquivo JSON\n",
        "        \"\"\"\n",
        "\n",
        "        with open(fileName, 'r') as f:\n",
        "            rawData = f.read()\n",
        "\n",
        "        data = json.loads(rawData)\n",
        "        return data\n",
        "        \n",
        "# Utilitário para formatar os dados de dia\n",
        "# Autor: Matheus Lemos <matheuslemosf@gmail.com>\n",
        "\n",
        "import datetime\n",
        "\n",
        "class DateFormat():\n",
        "    \"\"\" Classe para lidar com formatacão de datas\n",
        "    \"\"\"\n",
        "\n",
        "    def genDayDict(self):\n",
        "        \"\"\" Gera um dicionário dos dias \n",
        "        \"\"\"\n",
        "\n",
        "        # Variáveis\n",
        "        year = 2020\n",
        "        months = [31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31]\n",
        "        dayDict = {}\n",
        "        k = 1\n",
        "        \n",
        "        # Gera o dicionário\n",
        "        for i in range(0, len(months)):\n",
        "            j = 1\n",
        "            for j in range(1, months[i] + 1):\n",
        "                weekday = datetime.datetime(year, i + 1, j).weekday()\n",
        "                key = f\"{j}{i+1:02}\"\n",
        "                if weekday not in [5,6]:\n",
        "                    dayDict[key] = k\n",
        "                    k += 1\n",
        "        \n",
        "        return dayDict\n",
        "        \n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Do385-0_VeBd"
      },
      "source": [
        "# Arquivo da interface de texto\n",
        "# Autor: Matheus Lemos <matheuslemosf@gmail.com>\n",
        "\n",
        "# from model import Model\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "# from utils.fileDriver import FileDriver\n",
        "# from utils.dateFormat import DateFormat\n",
        "\n",
        "class Interface:\n",
        "    \"\"\"\n",
        "    Classe responsável pela interface e validacão de input\n",
        "    Arguments:\n",
        "        model {Model} -- Classe do modelo do tensorflow\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"\n",
        "        Assignment de variáveis\n",
        "        \"\"\"\n",
        "        self.parameters = {}\n",
        "        self.fileDriver = FileDriver()\n",
        "        self.dateFormat = DateFormat()\n",
        "        self.dias = self.dateFormat.genDayDict()\n",
        "\n",
        "    def handleFit(self):\n",
        "        \"\"\" Método responsável pelo treinamento e exibicão dos gráficos de treinamento do modelo\n",
        "        \"\"\"\n",
        "\n",
        "        # Parâmetros\n",
        "        parameterFileName = 'modelConfig.json'\n",
        "        \n",
        "        # Validacão e execucão\n",
        "        # try:\n",
        "        # Leitura do arquivo json de configuracões \n",
        "        config = self.fileDriver.readJson(parameterFileName)\n",
        "        dias = self.dias \n",
        "        \n",
        "        # Leitura dos dados CSV para datasets e labels\n",
        "        csvFileName = config['dataset']['filename']\n",
        "        model = Model(csvFileName)\n",
        "        data = model.load(dias)\n",
        "        \n",
        "        # Escreve os dados para uso posterior\n",
        "        model.write('traindata.csv', data)\n",
        "\n",
        "        # Normaliza os dados\n",
        "        normalizedData = model.normalize(data)\n",
        "        trainDataset, testDataset, trainLabels, testLabels = model.splitData(normalizedData, float(config['dataset']['split']))\n",
        "        \n",
        "        # Criacão e treinamento do modelo\n",
        "        model.fit(trainDataset, trainLabels, config['model'])\n",
        "\n",
        "        # Verificacão do modelo com dados de teste\n",
        "        predictions = model.predict(testDataset, testLabels, config['model'])\n",
        "        \n",
        "        # Gráfico predicoes x dia\n",
        "        trainData = np.array((trainLabels, trainDataset['dia'], trainDataset['hora'])).T\n",
        "        trainData = pd.DataFrame(trainData, columns=['fechamento', 'dia', 'hora'])\n",
        "\n",
        "        sns.regplot(x='dia', y='fechamento', data=predictions)\n",
        "        sns.regplot(x=\"dia\", y='fechamento', data=trainData)\n",
        "        plt.show()\n",
        "\n",
        "        # Gráfico predicoes x hora\n",
        "        sns.regplot(x='hora', y='fechamento', data=predictions)\n",
        "        sns.regplot(x=\"hora\", y='fechamento', data=trainData)\n",
        "        plt.show()\n",
        "\n",
        "        # except FileNotFoundError:\n",
        "        #     print(\"Arquivo não foi encontrado\")\n",
        "        \n",
        "    def handleValidate(self):\n",
        "        \"\"\" Método responsável pela previsão de novos dados a partir de dia requisitado\n",
        "        pelo usuário\n",
        "        \"\"\"\n",
        "\n",
        "        # Parâmetros\n",
        "        dia = input('Dia para que se deseja realizar predicão: ')\n",
        "        parameterFileName = 'modelConfig.json'\n",
        "\n",
        "        # try:\n",
        "        # Leitura do arquivo json de configuracão\n",
        "        config = self.fileDriver.readJson(parameterFileName)\n",
        "        dias = self.dias \n",
        "    \n",
        "        # Faz a predicão para esse único dado\n",
        "        model = Model()\n",
        "        model.validate(dia, config['model'], dias)\n",
        "\n",
        "        # except FileNotFoundError:\n",
        "        #     print(\"Arquivo não foi encontrado\")\n",
        "        # except KeyError:\n",
        "        #     print(\"Valor inválido - Dia informado não pode ser fim de semana\")\n",
        "\n",
        "    def getUserInput(self):\n",
        "        \"\"\"\n",
        "        Interface com o usuário\n",
        "        \"\"\"\n",
        "        # Variáveis\n",
        "        flag = False\n",
        "\n",
        "        inputString = \"\"\"Opcões:\n",
        "        0 - Treinar modelo\n",
        "        1 - Fazer predicões a partir de dados reais\n",
        "Sua opcão: \"\"\"\n",
        "\n",
        "        while flag is False:\n",
        "            option = input(inputString)\n",
        "\n",
        "            if option == '0':\n",
        "                flag = True\n",
        "                self.handleFit()\n",
        "            elif option == '1':\n",
        "                flag = True\n",
        "                self.handleValidate()\n",
        "            else:\n",
        "                print(\"Opcão inválida\")"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 557
        },
        "id": "qQN__46UVMVt",
        "outputId": "acb8a3f3-d7bc-44e1-833c-20ae5f0fb34b"
      },
      "source": [
        "# Arquivo principal do programa IA Trader\n",
        "# Autor: Matheus Lemos <matheuslemosf@gmail.com>\n",
        "\n",
        "# from model import Model\n",
        "# from interface import Interface\n",
        "\n",
        "def main():\n",
        "    \"\"\"\n",
        "    Funcão principal do projeto\n",
        "    \"\"\"\n",
        "    interface = Interface()\n",
        "    interface.getUserInput()\n",
        "\n",
        "main()"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Opcões:\n",
            "        0 - Treinar modelo\n",
            "        1 - Fazer predicões a partir de dados reais\n",
            "Sua opcão: 1\n",
            "Dia para que se deseja realizar predicão: 24\n",
            "dayDict\n",
            "{'101': 1, '201': 2, '301': 3, '601': 4, '701': 5, '801': 6, '901': 7, '1001': 8, '1301': 9, '1401': 10, '1501': 11, '1601': 12, '1701': 13, '2001': 14, '2101': 15, '2201': 16, '2301': 17, '2401': 18, '2701': 19, '2801': 20, '2901': 21, '3001': 22, '3101': 23, '302': 24, '402': 25, '502': 26, '602': 27, '702': 28, '1002': 29, '1102': 30, '1202': 31, '1302': 32, '1402': 33, '1702': 34, '1802': 35, '1902': 36, '2002': 37, '2102': 38, '2402': 39, '2502': 40, '2602': 41, '2702': 42, '2802': 43, '203': 44, '303': 45, '403': 46, '503': 47, '603': 48, '903': 49, '1003': 50, '1103': 51, '1203': 52, '1303': 53, '1603': 54, '1703': 55, '1803': 56, '1903': 57, '2003': 58, '2303': 59, '2403': 60, '2503': 61, '2603': 62, '2703': 63, '3003': 64, '3103': 65, '104': 66, '204': 67, '304': 68, '604': 69, '704': 70, '804': 71, '904': 72, '1004': 73, '1304': 74, '1404': 75, '1504': 76, '1604': 77, '1704': 78, '2004': 79, '2104': 80, '2204': 81, '2304': 82, '2404': 83, '2704': 84, '2804': 85, '2904': 86, '3004': 87, '105': 88, '405': 89, '505': 90, '605': 91, '705': 92, '805': 93, '1105': 94, '1205': 95, '1305': 96, '1405': 97, '1505': 98, '1805': 99, '1905': 100, '2005': 101, '2105': 102, '2205': 103, '2505': 104, '2605': 105, '2705': 106, '2805': 107, '2905': 108, '106': 109, '206': 110, '306': 111, '406': 112, '506': 113, '806': 114, '906': 115, '1006': 116, '1106': 117, '1206': 118, '1506': 119, '1606': 120, '1706': 121, '1806': 122, '1906': 123, '2206': 124, '2306': 125, '2406': 126, '2506': 127, '2606': 128, '2906': 129, '3006': 130, '107': 131, '207': 132, '307': 133, '607': 134, '707': 135, '807': 136, '907': 137, '1007': 138, '1307': 139, '1407': 140, '1507': 141, '1607': 142, '1707': 143, '2007': 144, '2107': 145, '2207': 146, '2307': 147, '2407': 148, '2707': 149, '2807': 150, '2907': 151, '3007': 152, '3107': 153, '308': 154, '408': 155, '508': 156, '608': 157, '708': 158, '1008': 159, '1108': 160, '1208': 161, '1308': 162, '1408': 163, '1708': 164, '1808': 165, '1908': 166, '2008': 167, '2108': 168, '2408': 169, '2508': 170, '2608': 171, '2708': 172, '2808': 173, '3108': 174, '109': 175, '209': 176, '309': 177, '409': 178, '709': 179, '809': 180, '909': 181, '1009': 182, '1109': 183, '1409': 184, '1509': 185, '1609': 186, '1709': 187, '1809': 188, '2109': 189, '2209': 190, '2309': 191, '2409': 192, '2509': 193, '2809': 194, '2909': 195, '3009': 196, '110': 197, '210': 198, '510': 199, '610': 200, '710': 201, '810': 202, '910': 203, '1210': 204, '1310': 205, '1410': 206, '1510': 207, '1610': 208, '1910': 209, '2010': 210, '2110': 211, '2210': 212, '2310': 213, '2610': 214, '2710': 215, '2810': 216, '2910': 217, '3010': 218, '211': 219, '311': 220, '411': 221, '511': 222, '611': 223, '911': 224, '1011': 225, '1111': 226, '1211': 227, '1311': 228, '1611': 229, '1711': 230, '1811': 231, '1911': 232, '2011': 233, '2311': 234, '2411': 235, '2511': 236, '2611': 237, '2711': 238, '3011': 239, '112': 240, '212': 241, '312': 242, '412': 243, '712': 244, '812': 245, '912': 246, '1012': 247, '1112': 248, '1412': 249, '1512': 250, '1612': 251, '1712': 252, '1812': 253, '2112': 254, '2212': 255, '2312': 256, '2412': 257, '2512': 258, '2812': 259, '2912': 260, '3012': 261, '3112': 262}\n",
            "df\n",
            "Transforma o dia baseado no dicionário de dias \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-68-8e0e824cea38>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0minterface\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetUserInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-68-8e0e824cea38>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     \"\"\"\n\u001b[1;32m     11\u001b[0m     \u001b[0minterface\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInterface\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0minterface\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetUserInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-43-3db1b379469e>\u001b[0m in \u001b[0;36mgetUserInput\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0moption\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'1'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m                 \u001b[0mflag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandleValidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Opcão inválida\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-43-3db1b379469e>\u001b[0m in \u001b[0;36mhandleValidate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;31m# Faz a predicão para esse único dado\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdia\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;31m# except FileNotFoundError:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-66-b0d43cb6dfa2>\u001b[0m in \u001b[0;36mvalidate\u001b[0;34m(self, dia, parameters, dayDict)\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Transforma o dia baseado no dicionário de dias '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0;31m# Transforma o dia baseado no dicionário de dias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m         \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dia'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dia'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdayDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0mnormalized\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[1;32m   4210\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4211\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4212\u001b[0;31m                 \u001b[0mmapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4214\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m<ipython-input-66-b0d43cb6dfa2>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Transforma o dia baseado no dicionário de dias '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0;31m# Transforma o dia baseado no dicionário de dias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m         \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dia'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dia'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdayDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0mnormalized\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: '24'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NGa4UyaZZEA3"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/MyDrive/JOBS/TENSORFLOW/')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}